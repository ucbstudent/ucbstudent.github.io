---
layout: post
title:  "Sparrow"
date:   2015-9-29 20:30
permalink: sparrow
---

The problem Sparrow is trying to address is low latency scheduling of jobs in
large compute clusters.  This is clearly a real and very important problem, it
would make stream processing systems like spark streaming that much more
practical, and would allow batch jobs to be spawned interactively by users,
opening up web applications to massive compute power at low latency.

The basic idea with Sparrow, is that in order to achieve low latency, we need
to abandon a total understanding of the system, and instead operate off of
statistical a statistical sample.  In practice, this means that if n jobs must
be scheduled, m workers will be queried for their state, but only the n least
loaded of them will be actually scheduled.  Therefore, statistically speaking,
less loaded nodes will be scheduled before heavily loaded nodes, leading to a
well balanced cluster.

I see two very important trade-offs here.  First, they're heavily dependent on
RTT of their network.  While it's safe to assume for spark in highly optimized
datacenters, RTT will be low, this somewhat limits generalization to internet
scale task scheduling applications should they arise someday.  Second,
fundamentally they have to give up some features to avoid understanding the
full state of the cluster.  One wonders if there's a mid-point where something
sparrow like could be used for latency sensitive tasks, while something more
heavy weight could be used otherwise.
